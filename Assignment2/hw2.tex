\documentclass[12pt]{article}%
\usepackage{amsfonts}
\usepackage{fancyhdr}
\usepackage{comment}
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2.2cm, right=2.2cm]%
{geometry}
\usepackage{times}
\usepackage{amsmath}
\usepackage{changepage}
\usepackage{stfloats}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{indentfirst}
\setlength{\parindent}{2em}
\setcounter{MaxMatrixCols}{30}
\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\textbf{#1.} }{\ \rule{0.5em}{0.5em}}

\usepackage{mathtools}

\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}

\begin{document}

\title{MATH2040C Homework 2}
\author{ZHENG Weijia (William, 1155124322)}
\date{\today}
\maketitle



\section{Section 1.6, Q12}

Given $\{u,v,w\}$ is a basis for $V$, then we have $\{u,v,w\}$ is linearly independent itself and $V =$ span$\{u,v,w\}$.

Note that hence $\forall x \in V, \exists a,b,c \in \mathbb{F}$ such that $x=au+bv+cw=a(u+v+w-(v+w))+b(v+w-w)+cw=a(u+v+w)+(b-a)(v+w)+(c-b)w.$

Hence $x\in$ span $\{u+v+w,v+w,w\}$, i.e., $V$=span$\{u,v,w\}$ $\subset $ span $\{u+v+w,v+w,w\}$. 

And span$\{u+v+w,v+w,w\}$ $\subset$ span$\{u,v,w\}$ holds trivially, hence $\{u+v+w,v+w,w\}$ spans $V.$

Remains to prove that $\{u+v+w,v+w,w\}$ is linearly independent, suppose not, $\exists d,e,f\in \mathbb{F}$ (not all zeros) such that $$d(u+v+w)+e(v+w)+fw=0_V,$$ where the $0_V$ is the zero vector of $V.$

which implies $$du+(d+e)v+(d+e+f)w=0_V.$$ 

Note that as supposed $d,e,f$ are not all zeros, hence $d,(d+e),(d+e+f)$ are not all zeros. 

Contradiction with the assumption that $\{u,v,w\}$ is linearly independent. 

Hence $\{u+v+w,v+w,w\}$ is linearly independent at the first place. 

Q.E.D.

~\ 

\section{Section 1.6, Q15}

We construct the basis by ourself. Let $B= D \cup A.$ 

$A=\{A_{mn}:m=1,2,...,n; n=1,2,...,n; m\neq n.\}$ where $A_{mn}[i,j]=1$ if $(i=m,j=n)$, else it is 0.

is a set of n by n matrices having all slot being zeros unless one slot not on the main diagnoal. 

And $D=\{D_1,D_2,...,D_{n-1}\}$, where $D_{k}[i,j] = 1$ if $(i=j=n $ or $ i=j=k)$, else is zero entry. 

Note that $\forall$ n by n matrix $M$ with $tr(M)=0.$ We have $$M=\sum_{i,j: i\neq j}M_{ij}A_{ij} + \sum_{i=1}^{n-1}M_{ii}D_i.$$ 

Also note that $B= D \cup A$ is linearly independent, and from above we have $$span{B}=\{M_{n \times n}:tr(M)=0\}.$$

Therefore $B$ is a basis of $\{M_{n \times n}:tr(M)=0\}.$ And $$|B|=|A|+|D|=n-1+n^2-n=n^2-1.$$

Q.E.D.

~\ 




\section{Section 1.6, Q26}

Consider the transform: $T: P_n(\mathbb{R})\to \mathbb{R}$, with the function $T(f)=f(a).$ 

. $\forall f_1,f_2 \in P_n(\mathbb{R}),$ $$T(f_1+f_2)=(f_1+f_2)(a)=f_1(a)+f_2(a)=T(f_1)+T(f_2).$$

And $\forall c \in \mathbb{R},$ $$T(cf)=cf(a).$$

We proved that the transformation is linear.

From the rank nullity theorem, $$\dim{N(T)}+\dim{R(T)}=\dim{P_n(\mathbb{R})}=n+1.$$

Note that $\dim{R(T)}=1$, hence $\dim{N(T)}=n.$ 

Note that $N(T)=\dim\{f\in P_n(\mathbb{R}) :f(a)=0\}.$ Therefore it is $n.$

Done. 

~\ 



\section{Section 1.6, Q30}

Note that the $0_V=\begin{pmatrix}
                        0 & 0
                        \\0 & 0
                    \end{pmatrix}$. And by definition, $0_V \in W_1,W_2.$

Note that $\forall x_1,x_2\in W_1$, $\exists a_1, a_2, b_1, b_2, c_1, c_2 \in F$ such that $x_1=\begin{pmatrix}
                                                                                        a_1 & b_1
                                                                                        \\c_1 & a_1
                                                                                        \end{pmatrix}$ and $x_2=\begin{pmatrix}
                                                                                                                    a_2 & b_2
                                                                                                                    \\c_2 & a_2
                                                                                                                    \end{pmatrix}$.

Note that $x_1+x_2=\begin{pmatrix}
                    a_1+ a_2 & b_1+b_2
                    \\c_1+c_2 & a_1+a_2
                    \end{pmatrix},$ which is also $\in W_1.$ And $\forall a \in F,$ $$ax_1=\begin{pmatrix}
                                                                                        aa_1 & ab_1
                                                                                        \\ac_1 & aa_1
                                                                                        \end{pmatrix} \in W_1.$$

Note that $\forall y_1,y_2\in W_2$, $\exists d_1,d_2,e_1,e_2 \in F$ such that $y_1=\begin{pmatrix}
                                                                                        0 & d_1
                                                                                        \\-d_1 & e_1
                                                                                        \end{pmatrix}$ and $y_2=\begin{pmatrix}
                                                                                            0 & d_2
                                                                                            \\-d_2 & e_2
                                                                                            \end{pmatrix}$ Hence $y_1+y_2=\begin{pmatrix}
                                                                                                                            0 & d_1 +d_2
                                                                                                                            \\-d_1+d_2 & e_1+e_2
                                                                                                                            \end{pmatrix} \in W_2.$ And $\forall a \in F,$ $$ay_1=\begin{pmatrix}
                                                                                                                                                                                    0 & ad_1 +ad_2
                                                                                                                                                                                    \\-ad_1+ad_2 & ae_1+ae_2
                                                                                                                                                                                    \end{pmatrix} \in W_2.$$

Therefore, both $W_1, W_2$ are subspaces of $V$. 

Note that a basis for $W_1$ can be $\{ \begin{pmatrix} 1 & 0 \\0 & 1 \end{pmatrix}, \begin{pmatrix} 0 & 1 \\0 & 0 \end{pmatrix}, \begin{pmatrix} 0 & 0 \\1 & 0 \end{pmatrix}  \}$. Hence $\dim{W_1}=3.$

A basis for $W_2$ can be $\{ \begin{pmatrix} 0 & 1 \\-1 & 0 \end{pmatrix}, \begin{pmatrix} 0 & 0 \\0 & 1 \end{pmatrix}\}.$ Hence $\dim{W_2}=2.$

$W_1 \cap W_2=\{\begin{pmatrix} 0 & a \\-a & 0 \end{pmatrix}: a \in F\},$ hence $\dim{W_1 \cap W_2}=1.$

$\forall \begin{pmatrix} a & b \\c & d \end{pmatrix} \in V,$ $$\begin{pmatrix} a & b \\c & d \end{pmatrix} = \begin{pmatrix} a & c+b \\0 & a \end{pmatrix}+\begin{pmatrix} 0 & -c \\c & d-a \end{pmatrix}.$$

The first term is element of $W_1$ and the second term is element of $W_2$. Hence $$\begin{pmatrix} a & b \\c & d \end{pmatrix} \in W_1+ W_2.$$

It is obvious that $W_1+W_2 \in V,$ then $W_1+W_2 = V.$ Hence $\dim{W_1+W_2}=\dim{V}=4.$ 

Done.

~\ 





\section{Section 2.1, Q3}

Note that $\forall (a_1,a_2),(b_1,b_2)\in \mathbb{R}^2,$ $T((a_1,a_2)+(b_1,b_2))=(a_1+b_1+a_2+b_2,0,2a_1+2b_1-a_2-b_2)=(a_1+a_2,0,2a_1-a_2)+(b_1+b_2,0,2b_1-b_2)=T((a_1,a_2))+T((b_1,b_2)).$

And also note that $\forall (a_1,a_2)\in \mathbb{R}^2, c \in \mathbb{R},$ $$T(c(a_1,a_2))=(ca_1+ca_2,0,2ca_1-ca_2)=c(a_1+a_2,0,2a_1-a_2)=cT((a_1,a_2).$$

Hence $T$ is linear. 

The basis for $N(T)$ is $\{(0,0)\}$, and $\dim{N(T)}=0.$ 

And a basis for $R(T)$ is $\{(1,0,2),(1,0,-1)\}.$ Hence $\dim{R(T)}=2.$

Note that $$\dim{R(T)}+\dim{N(T)}=2=\dim{R^2}$$. 

Therefore the rank nullity theorem is verified. 

Note that $(1,1,1) \notin R(T)$, hence $T$ is not onto (surjective). 

Also note that $N(T)={(0,0)},$ then $T$ is one-to-one (injective). 

Done. 

~ \ 

\section{Section 2.1, Q5}

Note that $\forall f(x),g(x) \in P_2(\mathbb{R}),$ we have $$T(f(x)+g(x))=x(f(x)+g(x))+(f(x)+g(x))'=xf(x)+f'(x)+xg(x)+g'(x)=T(f(x))+T(g(x)).$$

Also note that $\forall f(x)\in P_2(\mathbb{R}), \forall a\in \mathbb{R},$ $$T(af(x))=xaf(x)+af'(x)=aT(f(x)).$$

Therefore, $T$ is linear. 

Consider the $N(T),$ notice that $xf(x)+f'(x)=0$ does not hold if $f(x)$ is a nonzero polynomial, because the L.H.S. always have nonzero order. 

Hence the nullspace of $T$ is only $\{f(x)=0\}.$ 

And the basis for it is $\{f(x)=0\},\dim{\{f(x)=0\}}=0.$

A basis for $R(T)$ is $\{x^3+2x,x,x^2+1\}$ and hence $\dim{\{x^3+2x,x,x^2+1\}}=3$. 

Note that $\dim{R(T)}+\dim{N(T)}=0+3=\dim{P_2(\mathbb{R})}.$ Hence the rank nullity theorem is verified. 

Note that $N(T)=0,$ then $T$ is one-to-one (injective). 

Also note that $h(x)=2x^3+x^2+5x+1 \in P_3(\mathbb{R})$ but $h(x)\notin R(T).$ Hence $T$ is not an onto (surjective). 

Done. 

~\ 


\section{Section 2.1, Q14}

\subsection{(a)}

We prove the "only if" direction first. Suppose $T$ is injective. Then suppose $\exists$ a linearly independent subset $S \subset V$ such that $T(S)$ is not linearly independent.

Write $S=\{s_1,s_2,...,s_n\}.$ Then $T(S)=\{T(s_1),T(s_2),...,T(s_n)\},$ since $T(S)$ is linearly dependent. Then $\exists a_1,a_2,...,a_n \in F$ such that $$a_1T(s_1)+a_2T(s_2)+...a_nT(s_n)=0.$$

That is $$T(a_1s_1+a_2s_2+...a_ns_n)=0.$$

Recall that $T$ is injective, then the $N(T)$ contains only the zero vector. Then $a_1s_1+a_2s_2+...a_ns_n$ is the zero vector, which contradicts with the assumption that $S$ is linearly independent.

Therefore $\forall$ linearly independent subset $S \in V$, $T(S)$ is also linearly independent. 

~\ 

Then we prove the "if" part. Hence we are given that $\forall$ linearly independent subset $S \in V$, $T(S)$ is linearly independent follows.

Suppose $T$ is not one-to-one, then $\exists u\in V$ $(u\neq 0_V)$ such that $T(u)=0_W.$ 

Consider a set $\{u\},$ which is a singleton with a nonzero element, hence linearly independent, but $1\cdot T(u)=0_W,$ which contradicts with our assumption that $\forall$ linearly independent subset $S \in V$, $T(S)$ is linearly independent follows. 

Q.E.D.

~\

\subsection{(b)}

Note that from (a), the "only if" part of this question is proved directly. What remains to be proved is that if $T(S)$ is linearly independent, then $S$ is linearly independent. 

Write $S=\{s_1,s_2,...,s_n\}$

Suppose not, suppose $S$ is linearly dependent, then $\exists a_1,a_2,...,a_n$ (not all zero) such that $$a_1s_1+a_2s_2+...+a_ns_n=0.$$

Then $0_W=T(a_1s_1+a_2s_2+...+a_ns_n)=a_1T(s_1)+...+a_nT(s_n).$ Which implies that $T(S)$ is linearly dependent, contradicts with our assumption. Hence $S$ is linearly independent at the first place.

Q.E.D. 

~ \ 

\subsection{(c)}

Since $\beta=\{v_1,v_2,...,v_n\}$ is a basis, it is linearly independent. 

Suppose $T(\beta)=\{T(v_1),T(v_2),...,T(v_n)\}$ is linearly dependent, then $\exists a_1,...,a_n$ (not all zeros) such that $$a_1T(v_1)+...+a_nT(v_n)=0.$$

Which implies $T(a_1v_1+...+a_nv_n)=0.$ By $T$ is one-to-one, $a_1v_1+...+a_nv_n=0,$ which contradicts with our assumption that $\beta$ is linearly independent.

Hence $T(\beta)$ is linearly independent.

What remains to prove is that $W\subset span{T(\beta)}.$ 

Since $T$ is surjective, then $\forall w\in W, \exists v\in V$ such that $w=T(v).$ 

And $\exists b_1,...,b_n $ such that $$v=b_1v_1+...+b_nv_n.$$ 

Therefore, $$w=T(b_1v_1+...+b_nv_n)=b_1T(v_1)+...+b_nT(v_n)\in span{T(\beta)}.$$ 

Then we proved that $T(\beta)$ is a basis for W.

Q.E.D. 

~\ 



\section{Section 2.1, Q17}

\subsection{(b)}

By the rank-nullity theorem, we have $$\dim{N(T)}+\dim{R(T)}=\dim{V}.$$ 

Which implies $\dim{N(T)}=\dim{V}-\dim{R(T)}.$

Recall that $\dim{R(T)}\leq\dim{W},$ then $-\dim{R(T)}\geq-\dim{W}.$ 

Therefore, $\dim{N(T)}=\dim{V}-\dim{R(T)}\geq \dim{V}-\dim{W}>0.$ 

Note that being one-to-one requires that $\dim{N(T)}=0.$ Hence in this case, $T$ cannot be one-to-one.

Q.E.D. 

~\ 

\subsection{(a)}

Note that $T$ is onto iff $R(T)=W.$ Which implies $\dim{R(T)}=\dim{W}.$ This is impossible to achieve since $$\dim{R(T)}=\dim{V}-\dim{N(T)}<\dim{W}-\dim{N(T)}.$$ 

Hence $T$ cannot be onto. 

Q.E.D. 

~\ 


\section{Section 2.1, Q21}

\subsection{(a)}

$\forall a=(a_0,a_1,...),b=(b_0,b_1,...)\in V, \forall c \in F,$ we have $$T(a+b)=T(a_0+b_0,...)=(a_1+b_1,a_2+b_2,...)=(a_1,a_2,...)+(b_1,b_2,...)=T(a)+T(b).$$

And $$T(ca)=(ca_1,ca_2,...)=c(a_1,a_2,...)=cT(a).$$ 

Therefore $T$ is linear. 

$\forall a=(a_0,a_1,...),b=(b_0,b_1,...)\in V, \forall c \in F,$ we have $$U(a+b)=U(a_0+b_0,...)=(0,a_0+b_0,a_1+b_1,...)=(0,a_0,a_1,...)+(0,b_0,b_1,...)=U(a)+U(b).$$

And $$U(ca)=(ca_0,ca_1,...)=c(a_0,a_1,...)=cU(a).$$ 

Therefore $U$ is linear. 

Q.E.D. 

~\ 

\subsection{(b)}

Note that $\forall w \in V, \exists (1,w)\in V$ such that $$T((1,w))=w.$$ 

Therefore $T$ is surjective. 

Also note that $T((1,1,0,...))=T((0,1,0,...))=(1,0,...)$ (the ... part are all zeros) 

Therefore $T$ is not one-to-one, not injective. 

Q.E.D. 

~\ 

\subsection{(c)}

$\forall x,y\in V$ with $x \neq y$, we have $U(x)=(0,x)$ and $U(y)=(0,y).$ 

$U(x)\neq U(y)$ follows since $x\neq y. $ Therefore, $U$ is one-to-one. 

Also note that $(1,0,0,0,...)\in V$ (the ... part are all zeros) but obviously it does not inside the range of $U$. 

Hence $U$ is not onto. 

Q.E.D.

~ \ 

\section{Section 2.1, Q22}

\subsection{$T:\mathbb{R}^3 \to \mathbb{R}$}

Denote $a=T((1,0,0)),b=T((0,1,0)),c=T((0,0,1)).$ Then $\forall (x,y,z)\in \mathbb{R}^3$ we have $$T(x,y,z)=T(x(1,0,0)+y(0,1,0)+z(0,0,1))=ax+by+cz.$$

Which is what the question wanted. 

\subsection{$T:F^n \to F$}

To generate it to $F^n \to F,$ we need to first find a basis. 

Take the set $\{e_i,i=1,2,...n\}$ be the basis, where $e_i=(0,...1,...0)$ where the 1 is sloted at the i-th entry. 

Denote $T(e_i)=a_i.$ Then $\forall (x_1,x_2,...,x_n)\in F^n,$ $$T(x_1,x_2,...,x_n)=T(x_1e_1+x_2e_2+...+x_ne_n)=a_1x_1+a_2x_2+...+a_nx_n.$$

That's it. 

\subsection{$T:F^n \to F^m$}

Statement: $\exists u_1,u_2,...,u_n \in F^m$ such that $\forall (x_1,x_2,...,x_n)\in F^n,$ we have $$T((x_1,x_2,...,x_n))=x_1u_1+x_2u_2+...+x_nu_n.$$


Proof: denote $T(e_i)=u_i,$ then $\forall (x_1,x_2,...,x_n)\in F^n$, we have $$T((x_1,x_2,...,x_n))=T(x_1e_1+...+x_ne_n)=x_1u_1+x_2u_2+...+x_nu_n.$$

Q.E.D.


\end{document}
