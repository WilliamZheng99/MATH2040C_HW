\documentclass[12pt]{article}%
\usepackage{amsfonts}
\usepackage{fancyhdr}
\usepackage{comment}
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2.2cm, right=2.2cm]%
{geometry}
\usepackage{times}
\usepackage{amsmath}
\usepackage{changepage}
\usepackage{stfloats}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{indentfirst}
\setlength{\parindent}{2em}
\setcounter{MaxMatrixCols}{30}
\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\textbf{#1.} }{\ \rule{0.5em}{0.5em}}

\usepackage{mathtools}

\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}

\begin{document}

\title{MATH2040C Homework 5}
\author{ZHENG Weijia (William, 1155124322)}
\date{\today}
\maketitle



\section{Section 5.4, Q2(e)}

Let $w=\begin{pmatrix}2&4\\4&3\end{pmatrix}.$ Note that $w \in W$, because $w$ is symmetric.

Note that $T(w)=\begin{pmatrix}0&1\\1&0\end{pmatrix}\begin{pmatrix}2&4\\4&3\end{pmatrix}=\begin{pmatrix}4&3\\2&4\end{pmatrix},$ which is not symmetric, hence not belongs to $W$.

Therefore, by definition, $W$ is not a T-invariant subspace of $V.$

Done.


\section{Section 5.4, Q4}

$\forall g(t)$ belongs to polynomials, it can be expressed as for some $a_i,i=0,1,2,...,n$, $$g(t)=\sum_{i=0}^{n}a_i t^{i}.$$

Note that $\forall w \in W,$ we have $$g(T)(w)=\sum_{i=0}^{n}a_i T^{i}(w).$$

Because $W$ is itself a subspace, and note that $T^{i}(w) \in W, \forall i.$ Then $$\forall w \in W, g(T)(w)\in W.$$

Done.

\section{Section 5.4, Q6(d)}

Note that $z=\begin{pmatrix} 0&1\\1&0 \end{pmatrix}$, $T(z)=\begin{pmatrix} 1&1\\2&2\end{pmatrix}$ and $T^2(z)=3 \begin{pmatrix} 1&1\\2&2\end{pmatrix}.$

And hence $T^{k}(z)=3^{k-1}\begin{pmatrix} 1&1\\2&2\end{pmatrix}, \forall k\geq 1.$ 

Recall that $span\{z,T(z),T^2(z),\dots\}$ is the T-cyclic subspace of V generated by $z$.

Claim that $\{z,T(z)\}$ is a ordered basis for $span\{z,T(z),T^2(z),\dots\}$.

Note that $\forall u \in span\{z,T(z),T^2(z),\dots\},$ if $u=z$ or $u=T(z)$, then u are elements inside the basis set.

If $u=T^{k}(z)$ for some $k\geq 2,$ notice that $T^{k}(z)==3^{k-1}\begin{pmatrix} 1&1\\2&2\end{pmatrix}=3^{k-1}T(z).$

Therefore, $\{z,T(z)\}$ spans $span\{z,T(z),T^2(z),\dots\}$.

Done.

\section{Section 5.4, Q19}

According to the question, $A=\begin{pmatrix} 0&0&...&0&-a_0\\1&0&...&0&-a_1\\0&1&\dots&0&-a_2\\\dots&\dots&\dots&\dots&\dots\\0&0&...&0&-a_{k-2}\\0&0&\dots&1&-a_{k-1}\end{pmatrix}.$

Hence its characteristic polynomial is $\det{(A-tI)}$, which is $$\det \begin{pmatrix} -t&0&...&0&-a_0\\1&-t&...&0&-a_1\\0&1&\dots&0&-a_2\\\dots&\dots&\dots&\dots&\dots\\0&0&...&-t&-a_{k-2}\\0&0&\dots&1&-a_{k-1}-t\end{pmatrix}$$

We expand the massive matrix through the first column. 

Then the value is $$-t \det \begin{pmatrix} -t&0&...&0&-a_0\\1&-t&...&0&-a_1\\0&1&\dots&0&-a_2\\\dots&\dots&\dots&\dots&\dots\\0&0&...&-t&-a_{k-2}\\0&0&\dots&1&-a_{k-1}-t\end{pmatrix}+(-1)\det \begin{pmatrix} 0&0&...&0&-a_0\\1&-t&\dots&0&-a_2\\\dots&\dots&\dots&\dots&\dots\\0&0&...&-t&-a_{k-2}\\0&0&\dots&1&-a_{k-1}-t\end{pmatrix}.$$ 

Observe the second term recursively, we note that it is simply equal to $(-1)^k a_0.$

We keep spliting determinants from the left term, then we have $$\det (A-tI)=(-t)^{k-2}\det \begin{pmatrix} -t&-a_{k-2}\\1&-a_{k-1}-t\end{pmatrix}+(-1)^k (a_0+a_1t+ a_2 t^2 + a_{k-3}t^{k-3}).$$

$$=(-t)^{k-2}(t^2+ta_{k-1}+a_{k-2})+(-1)^k (a_0+a_1t+ a_2 t^2 + a_{k-3}t^{k-3}).$$

$$=(-1)^{k}(t^k + t^{k-1}a_{k-1} + t^{k-2}a_{k-2})+(-1)^k (a_0+a_1t+ a_2 t^2 + a_{k-3}t^{k-3}).$$

$$=(-1)^k (a_0 + a_1 t + a_2 t^2 +...a_{k-3}t^{k-3} +a_{k-2}t^{k-2}+a_{k-1}t^{k-1} + t^k ).$$

Done.

\section{Section 5.4, Q23}

As suggested by the question, we would like to use Mathematical Induction to tackle this problem.

Under the circumstance stated in the problem (note that those $v_i$'s are eigenvectors of T corresponding to distict eigenvalues), let mathematical statement $P(k)$ indicates that: 

$P(k):$ If $v_1+v_2+v_3+\dots v_k \in W,$ then $\forall i=1,2,\dots k, v_i \in W.$ 

We would prove the base case first: note that $P(1)$ holds trivially. 

Hence we can suppose that $\exists$ an integer $h$ such that $P(k)$ holds.

~\ 

In order to prove $P(k+1)$ holds, we need to prove $w_1+w_2+w_3+\dots w_k + w_{k+1} \in W$ implies $\forall i=1,2,\dots k, k+1,  v_i \in W.$ Where $w_j$'s are all eigenvectors of T corresponding to distict eigenvalues.

Suppose not, i.e., we suppose $\exists i=1,2,...,k,k+1$ such that $w_i \notin W$. 

WLOG, we let $w_1 \notin W.$

Note that the $P(k)$ holds, which implies that if $\exists i=1,2,...,k$ such that $w_i \notin W,$ then $w_1+w_2+\dots w_k \notin W.$

Inspect $w_{k+1}$, if $w_{k+1}\in W,$ then $w_1+w_2+\dots w_k \notin W.$ Which is impossible, hence $w_{k+1} \notin W.$

Repeating this process by grouping $w_1$ with other $k-1$ items among $w_2,w_3,...,w_{k+1},$ we can deduce that $$\forall i=1,2,...,k+1, w_{i} \notin W.$$

As supposed $w_1+w_2+\dots w_k + w_{k+1} \in W.$ Hence $T(w_1+w_2+\dots w_k + w_{k+1} )\in W.$ 

Which is $\sum_{i=1}^{k+1}\lambda_{i}w_i \in W$, subtract this with $w_1+...w_{k+1}$, we have $$\sum_{i=2}^{k+1}(\lambda_{i}-\lambda_1)w_{i} \in W.$$

We let T affect on it and subtract the first term out. Keep doing this process on and on, we eventually get $$\prod_{i=1}^{k}(\lambda_{k+1}-\lambda_i) \cdot w_{k+1} \in W.$$

Note that the $\lambda_i$'s are all distict, hence the coefficient is nonzero. Hence $w_{k+1} \in W.$

Which is contradicting with $w_{k+1} \notin W.$

Therefore, $\forall i=1,2,...,k,k+1$, $v_i \in W$ at the first place.

Hence $P(k)$ holds forall possible integer k under proper condition.

Done.


\section{Section 5.4, Q24}

Let $T:V\to V$, and $W$ be any T-invariant subspace of $V$. 

We choose the ordered basis for $V$ properly, such that each element in the order basis set $\beta$ is a eigenvector of $T$.

Let $\beta = \{v_{1,1},v_{1,2},\dots v_{1,m_1},\dots v_{k,1},v_{k,2},\dots v_{k,m_k}\}.$ Let $m_1+m_2+\dots m_k =m.$

Note that any (subspace of $V$)'s basis can be represented with elements from $\beta$. Then denote $W$'s basis set as $\gamma$.

Let $\dim \gamma=l$, then we have $l\leq m.$ Where $\gamma = \{w_1,w_2,\dots w_l\}$, those $w_a$'s are equal to some $v_{i,j}.$

WLOG, reorder $\gamma$ such that $\gamma=\{v_{1,1},\dots v_{1,q_1} , \dots v_{t,1},\dots v_{t,q_t}\}$. 

Where $v_{j,1},v_{j,2},\dots v_{j,q_j}$ are all corresponding to eigenvalue $\lambda_j.$ 

Therefore we have $q_1+\dots q_k =l.$ And the $q_i$ eigenvectors are corresponding to one distict eigenvalue.

Note that here the $q_i$ are $\lambda_i$'s geometric multiplicities (because they are number of corresponding eigenvectors), then we can have $$\forall i=1,2,\dots k, \mu_{T_{W}}(\lambda_i)=\gamma_{T_{W}}(\lambda_i). $$

Therefore, $T_W:W \to W$ must be diagnoalizable.

Done.

\section{Section 7.1, Q7(a)}

Note that $\forall x\in N(U),$ we have $$Ux=0.$$ 

Therefore $$U\cdot Ux = U^2(x)=0.$$

Hence $N(U) \subset N^2(U).$

Suppose $\exists$ an integer $k\geq 1$ such that $N^{k}(U) \subset N^{k+1}(U).$

Note that $\forall x \in N^{k}(U)$, $$U^{k+1}(x)=U\cdot U^{k}(x)=U(0)=0.$$

Therefore $x \in N^{k+1}(U).$

So, based on all above, we have $$N(U) \subset N^2(U) \subset N^3(U) \subset \dots \subset N^k(U) \subset N^{k+1}(U) \subset \dots .$$

Done.

\section{Section 7.1, Q7(c)}

Note that $\dim V- rank(U^m)=\dim ker(U^m)$ and $\dim V- rank(U^{m+1})=\dim ker(U^{m+1})$ hold because of rank-nullity theorem.

Under the condition of $rank(U^m)=rank(U^{m+1}),$ then $$\dim ker(U^m)=\dim ker(U^{m+1}).$$

Recall that $ker (U^m) \subset ker(U^{m+1})$, then we can deduce that $ker(U^m)=ker(U^{m+1}).$


~\ 

Let's inspect our situation at this stage, now we have $ker(U^m)=ker(U^{m+1})$, and we want to go one more step: to prove $$ker(U^{m+1})=ker(U^{m+2}).$$

Because $ker(U^{m+1}) \subset ker(U^{m+2}),$ we then have $$ker(U^{m+2}) = ker(U^{m+1}) \cup [ ker(U^{m+2}) - ker(U^{m+1})].$$

It is suffice to prove that the set $ker(U^{m+2}) - ker(U^{m+1})$ is an empty set.


~\ 


Let $x \in ker(U^{m+2}) - ker(U^{m+1})$, then we have $$U^{m+1}x \neq 0,~ U^{m+2}x =0.$$

Hence $U(U^{m+1}x)=0$ and $U^{m+1}x \in ker U$. And $U^{m+1}x \in R(U^{m+1}) \subset R(U^{m}).$

$\therefore \exists y \in V$ such that $$U^{m}y=U^{m+1}x.$$

Hence $U^{m+1}y=U(U^{m+1}x)=U^{m+2}x=0.$

$\because ker(U^m)=ker(U^{m+1})  \therefore U^m y=0.$

This implies that $ U^{m+1}x=0. $ This contradicts with the previous statement.

Therefore $$ker(U^{m+1})=ker(U^{m+2}).$$

By doing this repeatly, we can have $\forall k\geq m,$ $$ker(U^m)=ker(U^k).$$

Done.

\section{Section 7.1, Q7(b)}

Using the result of (c), since $\forall k\geq m,$ $$ker(U^m)=ker(U^k).$$ Then we have $\forall k\geq m$, 
$$rank(U^k)=\dim V - \dim ker(U^k) = \dim V - \dim ker(U^m)=rank(U^m).$$

Done.

\section{Section 7.1, Q7(d)}









\end{document}
